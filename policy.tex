\section{Enforcing Privacy Policies}\label{sec-policy}

\begin{figure}
\begin{Verbatim}
1. \textcolor{Purple}{def} \textbf{\textcolor{NavyBlue}{get_location}}():
2.   \textcolor{BrickRed}{"""}
3.   \textcolor{BrickRed}{Get raw location data from GPS, network or passive.}
4.   \textcolor{BrickRed}{"""}
5. 
6.   \textcolor{BrickRed}{# start the locating process} 
7.   sensorlib.request_data(\textcolor{BrickRed}{'startLocating'})
8.
9.   \textcolor{BrickRed}{# try to read current location}
10.  location = sensorlib.request_data(\textcolor{BrickRed}{'readLocation'})
11.
12.  \textcolor{BrickRed}{# stop the locating process} 
13.  sensorlib.request_data(\textcolor{BrickRed}{'stopLocating'})
14.
15.  \textcolor{Purple}{if not} location:
16.    \textcolor{Purple}{raise} LocationNotFoundException    
17.  
18.  \textcolor{Purple}{return} location
\end{Verbatim}
\caption{\small Sandbox implementation of \texttt{get\_location()}. 
\label{fig-getlocation}}
\end{figure}

In Sensibility Testbed, privacy policies are implemented as blurring layers, each layer acting as a 
reference monitor in a sandbox~\cite{ref} that enforces an access 
control policy over sensor access. Using the sandboxing 
technique in our prior work~\cite{cappos2010retaining}, we can 
interject code to control the behavior of sandbox functions, or 
system calls. A sensor access policy can (1) reduce 
the precision of the raw sensor data returned from a device, such
as returning the location of a nearest city rather than the device's exact location; (2) restrict 
the frequency of access to a sensor, such as the polling rate of a gyroscope or
a accelerometer, to avoid password interference~\cite{michalevsky2014gyrophone}; and (3) disable  
access to a certain sensor in sensitive situations, such as 
turning off a camera when a device is in a residential or work area.
Implementation of the last policy is still ongoing, so this paper will mainly address
how blurring levels allow for the execution of the first two types of policies. 

In Section~\ref{sec-repy}, we introduced the Repy sandbox briefly. 
In this section, we describe how Repy is implemented
(Section~\ref{sec-repy-ext}), and 
how to control the precision of sensor data (Section~\ref{sec-layer}), 
and the frequency of sensor access (Section~\ref{sec-nanny}).

\subsection{Secure Sandbox}\label{sec-repy-ext}

The Repy sandbox is an important part of device software 
(Section~\ref{sec-repy}). The sandbox is the execution environment 
of all experiment code. It isolates experimenters' programs from one 
another, and prevents any of the code from harming the device 
through its strong isolation techniques. More importantly, the sandbox
provides a flexible system call interposition technique where system call behavior 
can be modified. This allows us to define and implement
different data access policies. This section describes how Repy provides
security isolation and performance isolation, as well as customizable
sensor access policies.

\subsubsection{Security and Performance Isolation}

Repy, or Restricted Python, has a small, self-contained kernel as its trusted 
computing base (TCB). %unprivileged libraries and experiment code. 
Every system call in the TCB is strictly 
sanitized to preserve consistent behavior across different OSes, 
and to avoid uncommon corner cases that can be exploited. 
Furthermore, since the TCB is small (about 8,000 lines of code), it is 
less likely to have a kernel exploit than other more complex kernels. 
As a result, any vulnerability in an experiment 
%can at most cause compromise in the unprivileged portion of the sandbox, 
cannot escape the sandbox and perform malicious actions to 
the device system. The Repy sandbox exposes its system calls for accessing resources on a device
through a Python-like programming interface~\cite{repyv2} isolating experiment code from the kernel. 
%another way of saying this:
%Experiment code for accessing resources is contained by the 
%Repy sandbox, using its Python-like programming language interface.
This same sandbox design has been successfully running experiments as part of a network research 
testbed for more than six years, without significant operation faults or security breaches.
 ~\cite{seattle}. \yanyan{Justin thinks this statement is weak.} \lois(I don't know if this answers his concerns since the meaning is essentially the same)

In addition to security isolation,
%The sandbox exposes a programming 
%interface to experimenter programs to access 
%resources on the device. 
the sandbox provides performance isolation by
%by using OS hooks to monitor and control the amount of 
%CPU and memory used by a sandboxed program. To restrict 
%other resources, such as network and disk I/O, the sandbox 
interposition on system calls~\cite{garfinkel2003traps} that 
use resources, such as network and disk I/O, and preventing 
or delaying the execution of these calls if they exceed 
their configured quota. 
%As a result, this sandbox limits 
%what a sandboxed program can do. For example, 
This isolation means the sandbox can set access limits. For example, reading from and writing to the file system can
only occur in a per-experiment directory, sending and receiving
data via the network interface cannot exceed a configured rate, and 
CPU, memory and battery consumption cannot exceed a set level.
Therefore, the sandbox isolates the experiment program from 
the rest of the device. Due to this isolation, different researchers can run experiments on 
different sandboxes on the same device, without any interference between the studies.


\subsubsection{Sensor Access from the Python Sandbox}

%In the use cases in Section~\ref{sec-scenario}, when Alice starts 
%the Sensibility Testbed app, the native code in the app initializes a
%Python interpreter, launches the Repy sandbox, and starts the 
%communication between the device and the clearinghouse. The 
%sandbox's API provides calls to file system, networking, 
%threading functions, and so on. Therefore, Bob's code can read 
%files, send data through the network, etc., from Alice's device. 
%As in Section~\ref{sec-repy}, the Repy sandbox does not include 
%calls to access sensors. But 
To allow an experimenter's code to access sensors, such as 
GPS, WiFi, Bluetooth, accelerometer, and cellular network, we  
need access to native Android code. \lois(I think I already asked this, but does this only run on Android devices? If so, I think that needs to be mentioned. Also, when you say "we need access to Android code, who is "we?" The researchers? The user? Repy management?) We first implemented a set of sensor functions using 
Java in the native portion of the Sensibility Testbed app \lois(Again, who implemented the sensors? And are you referring to the design initially done that is now in the oast? Or the actions taken by a user now) The Repy 
sandbox then uses a Remote Procedure Call (RPC) to invoke the
corresponding Java code, and returns the data 
to a sandboxed Repy program. This defines a set of sensor APIs in 
Repy's programming language, such as \path{get_location()}, 
\path{get_accelerometer()}, \path{get_wifi()}, etc. 

Figure~\ref{fig-getlocation} shows how \path{get_location()} 
is defined as a sandbox function to get unfiltered location 
information from a mobile device. 
On line 7, \path{sensorlib.request_data()} is an RPC call 
defined in Repy, 
%\path{sensor_socket} is the socket for the Repy code to communicate with the native code, 
and \path{startLocating} is the name of the native Java method that tells the Android 
location manager to start looking up location information. Lines 10 and 13 are similar RPC 
calls that read location information from the Android location manager, and stops the location 
lookup. The command \path{get_location()} thus %is defined in the namespace of the sandbox kernel, it 
can be directly used by an experimenter in an experiment program if no blurring layer is in place.

A full list of sensor API is documented at~\cite{sensor-api}. The set
of sensors range from battery, Bluetooth, and cellular, to location, WiFi, 
accelerometer, and so on. 
As such, the original Repy interface and the added sensor API together 
provide the complete \textit{OS level} sandbox kernel on a mobile 
device, as shown in Figure~\ref{fig-blur}.

\begin{figure}
\center{\includegraphics[width=\columnwidth]{figs/blur.pdf}}
%\vspace*{-20pt}
\caption{\small Policy stack demonstrating how Sensibility Testbed implements blur policies. \yanyan{maybe replot}
\label{fig-blur}}
\end{figure}

\subsubsection{Policy Stack}
The sandbox kernel determines how IRB policies are implemented by affecting system calls. It can
interpose on a call and modify the data returned, or control the frequency with which a call can be made over
a period of time. 
%Different policies implemented can be stacked in tandem to 
%control different sensor accesses, like in Figure~\ref{fig-blur}.
%As mentioned above, Bob provided his IRB policies through our clearinghouse.
%Before Bob runs his experiment, the clearinghouse loads the access policies and instructs the sandbox on Alice's device to
%restrict sensor access accordingly. 
%
%Using the \path{get_location()} call as an example, 
%when Bob's code requests location data from Alice's device, the Repy sandbox first
%invokes the location-related Android code. 
%%(line 10 in Figure~\ref{fig-getlocation}). 
%When the location data is returned, according to Bob's IRB policy
%indicates that the returned location coordinates should be blurred to the nearest city to Alice's
%device, instead of her actual location. As a result, 
%For example, the sandbox returns a perturbed location that is less accurate, 
%%Furthermore, as Bob's IRB policy disallows collecting information about cell tower IDs, 
%%blocks any access to cell IDs, 
%%by another policy. Similarly, other information
%blurs a WiFi SSID to a hashed string, and restricts the frequency to access a
%gyroscope to prevent inferring passwords~\cite{michalevsky2014gyrophone}, and so on. 
Each policy is a blurring layer, which acts as an isolated and 
contained reference monitor. Different policies can be customized 
by loading individual blurring layers in order, as a policy stack. 

By design, a lower layer in the stack is the ancestor of 
a higher layer. Each blurring layer is untrusted by its ancestor layers, 
but is trusted by its descendant layers. In addition, every layer in the stack inherits the policy 
defined by its ancestor layer. The lowest blurring layer with no ancestors is the 
Sensibility Testbed's sandbox kernel. The experiment program runs at the top 
of the policy stack, thereby inheriting all the policies defined by the
lower layers, as shown in Figure~\ref{fig-blur}. 
Each policy stack acts as a set 
of filters for different sensors through which a call must pass before a sandboxed program can
access the sensor data. Different stacks can be customized for 
different IRB policies.


%In the following, we describe how to implement each blurring layer, 
%and use them to form a policy stack.

\subsection{Blurring Layers: Reducing Data Precision}\label{sec-layer}

%\yanyan{TODO: replace all security layers with blurring layers. fix the line wrapping.}
%The Sensibility Testbed uses an extended version of the Repy sandbox, whose 
%security mechanism is described in our prior work by Cappos, {\it et 
%al}~\cite{cappos2010retaining}. This section briefly explains this sandboxing 
%technique, and how it is used in Sensibility Testbed.

%In Sensibility Testbed, we construct a researcher's IRB policies as a set of 
%isolated and contained reference monitors called blurring layers. They each
%implement one IRB policy, and can 
%be stacked together to form a policy stack. 

Policies are implemented by each blurring layer via a \textit{virtual 
namespace} that provides function mapping to substitute raw 
data access with restricted data access. 
%and the boundary between two blurring layers is monitored by an 
%\textit{encasement library} that verifies interface semantics at runtime. 
To ensure the runtime behavior of each function mapping (for example, 
a function mapping of \path{get_location()} still returns location data), 
every blurring layer uses a \textit{contract} to verify the interface 
semantics between the blurring layers.

\subsubsection{Virtual Namespace}

The virtual namespace of each blurring layer executes the code in descendant 
layers with the corresponding layer's function mapping. By our convention, 
the virtual namespace of a blurring layer does not contain functions from the 
sandbox kernel or the namespace of its parent layer, unless explicitly 
specified by the mapping. \yanyan{why is this statement needed?}
For example, if a layer \path{foo} with 
functions \path{get_battery()}, \path{get_accelerometer()}, and 
\path{restricted_get_accelerometer()} were to instantiate a descendant 
layer \path{bar} with a function mapping 

\begin{Verbatim}
\{
\textcolor{BrickRed}{'get_battery'}: get_battery, 
\textcolor{BrickRed}{'get_accelerometer'}: restricted_get_accelerometer
\}
\end{Verbatim}
then the module \path{bar} would have access
to \path{foo.get_battery} via the name \path{get_battery}, and to
\path{foo.restricted_get_accelerometer} via the name 
\path{get_accelerometer}. That is, the function on the left of the colon \texttt{:}
\textit{replaces} the function on the right via the virtual namespace. 
In this case, layer \path{bar} would not be able to access 
\path{foo.get_accelerometer}.

\subsubsection{Contract}

%The virtual namespace is useful for loading
%code dynamically, but does not provide adequate security for
%use as an isolation boundary. The encasement library in the 
%Repy sandbox provides isolation between virtual namespaces. 
%Security layers do not share objects or functions.
%The encasement library copies all objects that are passed
%between security layers.
%
Each function call that can be sent by descendant blurring
layers needs to have its arguments return value, and 
other runtime behavior verified. This concept is similar to system call filtering
mechanisms~\cite{acharya2000mapbox, fraser2000hardening} 
that mediate access to a sensitive function interface. In our case, 
the functions are calls to smartphone sensors that 
can potentially reveal a device owner's private information. Our 
verification process uses a contract. For each function that has a 
mapping, the contract lists the number 
and types of its arguments, the exceptions that can be raised 
by the function, and the return type of the function\footnote{\scriptsize 
Since Python is a dynamically-typed language, it is useful to type check 
a function's arguments, exceptions, and return values.

A contract is represented as a Python dictionary in Repy. As an example, if 
the blurring layer \path{foo} wanted to create a contract that would map
\path{get_battery()} and \path{restricted_get_accelerometer()} into 
a new namespace, the contract would be: 

\begin{Verbatim}
\{\textcolor{BrickRed}{'get_battery'}: \{
  \textcolor{BrickRed}{'type'}: \textcolor{BrickRed}{'func'},
  \textcolor{BrickRed}{'args'}: \textcolor{Purple}{None}, 
  \textcolor{BrickRed}{'exceptions'}: (\textcolor{Purple}{BatteryNotFoundError}), 
  \textcolor{BrickRed}{'return'}: dict,
  \textcolor{BrickRed}{'target'}: get_battery
  \}, 
\textcolor{BrickRed}{'get_accelerometer'}: \{
  \textcolor{BrickRed}{'type'}: \textcolor{BrickRed}{'func'},
  \textcolor{BrickRed}{'args'}: str, 
  \textcolor{BrickRed}{'exceptions'}: (\textcolor{Purple}{ValueError}), 
  \textcolor{BrickRed}{'return'}: list,
  \textcolor{BrickRed}{'target'}: restricted_get_accelerometer
  \}
\}
\end{Verbatim} 

Note that the symbols in the contract come from \path{foo}'s 
namespace. Thus the target for the \path{get_battery} in the 
contract is the \path{foo.get_battery} function. Similarly, the 
target for the \path{get_accelerometer} in the contract is the 
\path{foo.restricted_get_accelerometer}.

Whenever an experiment calls a function, such as \path{get_battery}
or \path{get_accelerometer}, a verification process must perform 
type-checking using the contract. If the verification process 
detects a semantic violation, \yanyan{add an example} the entire experiment program is 
terminated. This guarantees that to a sandboxed program, 
the implemented policies do not change a function's semantics.
%In addition to type checking, the verification function copies 
%arguments and return values of mutable types to prevent 
%time-of-check-to-time-of-use bugs. Since mutable types are 
%copied, the caller cannot cause a race condition by modifying objects.


Each blurring layer provides a contract to instantiate the 
next blurring layer by substituting a version of the function that 
enforces a given policy. All descendant layers (layers loaded 
after this layer) will have access to the version of the function 
that enforces this new policy. The final blurring layer starts the 
experiment program with the appropriate set of functions. 
Therefore, the experimenter's program is forced to use all the 
new policies. An example of blurring layer implementation is given in 
Section~\ref{sec-precision-example}.  

%\subsubsection{Blurring Layer Instantiation}
\bigskip
From start to finish, the entire process proceeds as follows. 
The clearinghouse creates a list of access policies for a researcher's
experiment, according to the specified IRB policies. The sandbox on a mobile device, under the control of
this experimenter, obtains a list of command-line arguments 
from the clearinghouse, which includes all the blurring layers
and parameters for each layer. The pre-set blurring layer determine
the type of policy required, such as accelerometer access rate, and the 
IRB parameters customize the specific policy, such as accessing
an accelerometer at a rate of 50 times/second. 
%the first of which must be the encasement library.
%The kernel reads in the encasement library code and uses
%the virtual namespace abstraction to execute the code with
%the exported kernel functions. The encasement library
The sandbox then %uses its blurring layer creation call to 
instantiates 
the first blurring layer according to its contract, i.e., the function 
mapping that contains the kernel's exported functions.
%the security layer instantiation call, and the remaining
%command-line arguments. 
The newly instantiated blurring layer repeats this process 
%using the 
%encasement library's
%blurring layer creation call 
to instantiate the next
security layer with a potentially updated contract and function
mapping. Eventually, the experimenter's program is instantiated
in a separate layer with the functions provided
through the stack of blurring layers that preceded it.
The experimenter's program will then be subject to all the 
policies defined in the preceding layers, or the policy stack.

\subsubsection{An Example of Policy Implementation}
\label{sec-precision-example}

%\subsubsection{Reducing Data Precision}

Below is an an example of the implementation of a location blurring layer. 
When experimenter Bob requests a device, the clearinghouse recognizes that all the location data he 
collects must be substituted with a blurred location that only identifies the nearest city.
%rather than the exact location of the device. 
Therefore, the following blurring layer is
automatically loaded, along with Bob's experiment code, to map 
the \path{get_location()} call in Figure~\ref{fig-getlocation} to a version 
that implements such a policy. \yanyan{load code or load policy text? how
to translate policy text to code?}In the following, we name this
blurring layer \path{blur_to_city}, and assume it is the first descendant
of the sandbox kernel.

\begin{Verbatim}
1. \textcolor{Purple}{def} \textbf{\textcolor{NavyBlue}{get_city_location}}():
2.   \textcolor{BrickRed}{"""}
3.   \textcolor{BrickRed}{This function replaces the exact coordinates of} 
4.   \textcolor{BrickRed}{the Android device with the coordinates for the } 
5.   \textcolor{BrickRed}{geographic center of the nearest city.}
6.   \textcolor{BrickRed}{"""}
7.
8.   location = get_location()
9.
10.  closest_city = find_closest_city(location[\textcolor{BrickRed}{"latitude"}],
11.    location[\textcolor{BrickRed}{"longitude"}])
12.
13.  location[\textcolor{BrickRed}{"latitude"}] = closest_city[\textcolor{BrickRed}{"latitude"}]
14.  location[\textcolor{BrickRed}{"longitude"}] = closest_city[\textcolor{BrickRed}{"longitude"}]
15.
16.  \textcolor{Purple}{return} location
17.
18. \textcolor{BrickRed}{# Substitute get_location with get_city_location.}
19. \textbf{CHILD_CONTEXT_DEF[\textcolor{BrickRed}{"get_location"}] = \{}
20.    \textbf{\textcolor{BrickRed}{"type"}: \textcolor{BrickRed}{"func"},}
21.    \textbf{\textcolor{BrickRed}{"args"}: \textcolor{Purple}{None},}
22.    \textbf{\textcolor{BrickRed}{"return"}: \textcolor{Purple}{dict},}
23.    \textbf{\textcolor{BrickRed}{"exceptions"}: \textcolor{BrickRed}{"any"},}
24.    \textbf{\textcolor{BrickRed}{"target"}: get_city_location,}
25. \textbf{\}}
26.
27. \textbf{secure_dispatch_module()}
\end{Verbatim}


Line 1 -- 16 defines a new function named \path{get_city_location()} which returns 
the nearest city to the device. On line 10 -- 11, the function \path{find_closest_city()}
uses a quadtree-like algorithm~\cite{gruteser2003anonymous} that subdivides 
the area around the device until the area contains at least a city.
This algorithm can be applied similarly if a policy requires location 
precision at the state/province or country level.
%in \path{blur_to_city}'s namespace that is outside the sandbox kernel. 
Lines 19 -- 25 defines a contract for \path{get_city_location()}. 
%and stores it in a global dictionary \path{CHILD_CONTEXT_DEF}. 
In this contract, 
%the target for the sandbox kernel function 
%\path{get_location()} (line 19) is \path{get_city_location()} (line 24).
%This means that 
\path{get_city_location()} will substitute \path{get_location()} defined 
in the Repy sandbox kernel (line 19).
%On Line 19, \path{CHILD_CONTEXT_DEF} indicates that this data structure is to replace the
%Repy library function \path{get_location()}. 
Line 20 - 23 define the function's type, arguments,
return values, and any potential exceptions for runtime verification. 
%Line 24 indicates that Repy library function
%\path{get_location()} will be replaced by \path{get_city_location()} defined in line 1 - 16, once
%this blurring layer is in effect, which means the blurring layer is enforced via running along a
%sandboxed program. Finally, in order for this blurring layer to take effect, we need to call
Finally, \path{secure_dispatch_module()} (line 27) instantiates this
\path{blur_to_city} layer, when running along with the sandbox kernel. 
\yanyan{or does it instantiate experiment code?}As a result, 
whenever Bob's experiment code calls \path{get_location()}, 
the \path{blur_to_city} layer replaces it with \path{get_city_location()}. 

Similarly, because Bob's IRB policy disallows access to cell ID, another blurring layer 
can substitute the \path{get_cellID()} call in the sandbox kernel with a function that
returns \path{None}. This layer can be instantiated by \path{blur_to_city}
as its descendant, or by any other layer. An arbitrary number of layers can 
be stacked together to implement an experimenter's policies.

As the experiment code uses the same function call as defined by the sandbox, 
and only the blurring layers change the function's behavior, 
such policy enforcement is opaque to all the experimenters who run 
sandboxed programs in Sensibility Testbed.

\subsection{Nanny: Restricting Data Access Frequency}\label{sec-nanny}

Reducing data precision partially protects a device owner's privacy. However, frequent access to device sensor data 
can be another channel to snoop on personal information.
If sensor queries are made on a sufficiently frequent basis, they can be used
to track an individual's activities. The goal of reducing sensor access frequency 
is to prevent an accumulation of identifiable information about an individual, such as 
location~\cite{gruteser2003anonymous}, wireless network identifiers, and even 
accelerometer data. (Note that specific
details as to how frequently a certain sensor can be accessed without risking such an 
invasion is out of the scope of this work). 
Furthermore, the battery power of a device can 
be drained faster if sensors are accessed
with unnecessary frequency. Therefore, restricting the data access rate 
mandates that experiments collect data only as often as is necessary. 
To achieve this, the Repy sandbox provides a second mechanism
called \path{nanny} that mediates and restricts access frequency to sensors. 

\subsubsection{Restricting Access Rate}

\path{nanny} treats all sensors as \textit{resources}, and the function calls to 
access the sensors as the \textit{usage} of resources. 
%\path{nanny}'s control 
%mechanism for a resource is to limit the \textit{rate} of its usage. For example, 
When an 
%Utilization is controlled over one or more periods, where
experiment program's use of a resource is above a given threshold, 
\path{nanny} pauses the 
program for as long as required to, on average, return the rate to below the
threshold. Therefore, if an experiment program attempts to 
use a resource at a rate faster than is allowed by a policy, the function 
call is blocked until sufficient time has passed to average out the overall access rate. 

To monitor and control the usage of resources, \path{nanny} keeps a 
table of resource assignments that tracks and updates requests and releases. 
Once resource caps are set, an experiment program can never call a 
function to access a sensor more frequently than the cap. 
%A function call 
%request can be met only if the frequency is no greater than the cap. 

\subsubsection{An Example of Policy Implementation}\label{sec-rate-example}

Restricting access rate can also be implemented as a 
blurring layer, in a similar way as reducing the data precision.
Recall that in Section~\ref{sec-scenario}, Bob's IRB policy requires that
his experiment can get location updates every 10 minutes (600 seconds). 
Therefore, the following blurring layer is automatically loaded along with 
Bob's experiment code (likely as a descendant of another layer). In 
the following, we name this blurring layer \path{restrict_location}.

\begin{Verbatim}
1.  \textcolor{BrickRed}{# allow get_location call once per 600 seconds}
2.  \textbf{resourcesdict = \{\textcolor{BrickRed}{'get_location'}: 1.0/600\}} 
3.
4.  \textbf{nanny.start_resource_nanny(resourcesdict)}
5.
6.  \textcolor{Purple}{def} \textbf{\textcolor{NavyBlue}{restricted_get_location}}():
7.    \textbf{nanny.tattle_quantity(\textcolor{BrickRed}{'get_location'}, 1)}
8.    location_data = get_location()
9.    return location_data
10.
11. CHILD_CONTEXT_DEF[\textcolor{BrickRed}{"get_location"}] = \{
12.   \textcolor{BrickRed}{"type"}: \textcolor{BrickRed}{"func"},
13.   \textcolor{BrickRed}{"args"}: \textcolor{Purple}{None},
14.   \textcolor{BrickRed}{"return"}: \textcolor{Purple}{dict},
15.   \textcolor{BrickRed}{"exceptions"}: \textcolor{BrickRed}{"any"},
16.   \textcolor{BrickRed}{"target"}:  restricted_get_location,
17. \}
18. 
19. secure_dispatch_module()
\end{Verbatim}

Line 2 above defines a resource assignment table, \path{re- sourcesdict}, to track and update 
the function call to \path{get_location()}. It restricts the frequency to 
call \path{get_location()} to once per 600 seconds (note that 
600 seconds is filled in by Bob, and parsed by the clearinghouse as a blurring layer 
parameter to \path{restrict_location}, as in Section~\ref{sec-ch}). Line 4 initializes \path{nanny} 
with the resource assignment table, and line 6 -- 9 defines a 
function called \path{restricted_get_location()} that restricts location updates. 
The \path{tattle_quantity()} call on line 7 charges \textit{one usage} of \path{get_location()} 
call. It tells \path{nanny} that in \path{restricted_get_location()}, 
\path{get_location()} (line 8) will be called exactly once. The
next time this experiment program 
%calls \path{get_location()} again, the program 
will be paused for 600 seconds before it can call \path{get_location()} again,
as defined by \path{resourcesdict}.

The contract on line 11 -- 17 defines that the target
for \path{get_location()} is \path{restricted_get_location()}. If 
\path{restrict_location} is the first descendant of the sandbox kernel, then
\path{restricted_get_location()} will replace the \path{get_location()}
in the sandbox virtual namespace. If there is a preceding blurring layer 
before \path{restrict_location} that already updated its 
function mapping for \path{get_location()} (like \path{blur_to_city}  
in Section~\ref{sec-precision-example}), then
\path{restricted_get_location()} will replace the \path{get_location()} call
with the policy implemented in this preceding blurring layer. As a result, 
the experiment code will get location updates once per 10 minutes, at
the city level. 
%This is because layers \path{blur_to_city} and 
%\path{restrict_location} are both used in the policy stack.

\bigskip
The mechanisms in this section are all transparent to the experimenters 
and device owners, as the implementation of policies is controlled by the 
clearinghouse on behalf of the experimenters. An experimenter is aware 
of certain policies in place, but does not need to implement or explicitly
enforce such policies. 